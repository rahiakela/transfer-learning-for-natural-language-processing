{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-BERT-based-models-for-email-sentiment-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBmMTgf4L3bam6ZloEPOyR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transfer-learning-for-natural-language-processing/blob/main/2-getting-started-with-baselines/5_BERT_based_models_for_email_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0syenf2nUMgZ"
      },
      "source": [
        "# BERT based models for Email Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tvj1R7TUOC2"
      },
      "source": [
        "Our goal is to establish a set of baselines for a pair of concrete NLP problems, which we will later be able to use to measure progressive improvements gained from leveraging increasingly sophisticated transfer learning\r\n",
        "approaches. In the process of doing this, we aim to advance your general NLP instincts and refresh your understanding of typical procedures involved in setting up problem-solving pipelines for such problems. You will review techniques ranging from tokenization to data structure and model selection. We first train some traditional machine learning models from scratch to establish some preliminary baselines for these problems.\r\n",
        "\r\n",
        "We will focus on a pair of important representative example NLP problems – spam\r\n",
        "classification of email, and sentiment classification of movie reviews. This exercise will arm you with a number of important skills, including some tips for obtaining, visualizing and preprocessing data. \r\n",
        "\r\n",
        "Three major model classes will be covered, namely linear models such as logistic regression, decision-tree-based models such as random forests, and neural-network-based models such as ELMo. These classes are additionally represented by support vector machines (SVMs) with linear kernels, gradient-boosting machines (GBMs) and BERT respectively. \r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/transfer-learning-for-natural-language-processing/content-classification-supervised-models.png?raw=1' width='800'/>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inPFIdfP7n4K"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Pp-FuGn8Ej"
      },
      "source": [
        "Ref: https://stackoverflow.com/questions/57742410/error-on-scope-variable-while-using-tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7SakR1eElHP"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "pip install keras==2.2.4 # critical dependency\r\n",
        "pip install tensorflow==1.15\r\n",
        "pip install \"tensorflow_hub>=0.6.0\"\r\n",
        "pip install -q bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlt8No657pZ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3f6b4c23-bb24-4774-fd4a-4285035ca318"
      },
      "source": [
        "import numpy as np  # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import email        # email package for processing email messages\r\n",
        "import random\r\n",
        "import re\r\n",
        "import time\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "from bert.tokenization import FullTokenizer\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzDJNq2Xkz29"
      },
      "source": [
        "# Initialize tensorflow session\r\n",
        "sess = tf.Session()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ8un4hI7uw1",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "51d853c0-5b9f-45bf-e5c0-e1c6d4453efb"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload() # upload kaggle.json file"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2907116a-5fdd-45dc-8931-6410f3556cc2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2907116a-5fdd-45dc-8931-6410f3556cc2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"rahiakela\",\"key\":\"484f91b2ebc194b0bff8ab8777c1ebff\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKVZMbo7va7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b841ef17-aa25-4cd3-e187-4a5b511d40f2"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "mkdir -p ~/.kaggle\r\n",
        "mv kaggle.json ~/.kaggle/\r\n",
        "ls ~/.kaggle\r\n",
        "chmod 600 /root/.kaggle/kaggle.json\r\n",
        "\r\n",
        "# download dataset from kaggle\r\n",
        "kaggle datasets download -d wcukierski/enron-email-dataset\r\n",
        "unzip -qq enron-email-dataset.zip\r\n",
        "\r\n",
        "kaggle datasets download -d rtatman/fraudulent-email-corpus\r\n",
        "unzip -qq fraudulent-email-corpus.zip\r\n",
        "\r\n",
        "rm -rf enron-email-dataset.zip fraudulent-email-corpus.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "Downloading enron-email-dataset.zip to /content\n",
            " 99% 356M/358M [00:15<00:00, 4.21MB/s]\n",
            "100% 358M/358M [00:15<00:00, 24.6MB/s]\n",
            "Downloading fraudulent-email-corpus.zip to /content\n",
            " 91% 5.00M/5.52M [00:00<00:00, 7.45MB/s]\n",
            "100% 5.52M/5.52M [00:00<00:00, 8.08MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srh_wOUmwefT"
      },
      "source": [
        "def extract_messages(df):\r\n",
        "  messages = []\r\n",
        "  for item in df[\"message\"]:\r\n",
        "    # Return a message object structure from a string\r\n",
        "    e = email.message_from_string(item)\r\n",
        "    # get message body\r\n",
        "    message_body = e.get_payload()\r\n",
        "    messages.append(message_body)\r\n",
        "  print(\"Successfully retrieved message body from e-mails!\")\r\n",
        "  return messages"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQbAbRM7Wtfs"
      },
      "source": [
        "## Preprocessing Email Spam Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HplaHzeVWwfg"
      },
      "source": [
        "Here, we are interested in developing an algorithm that can detect whether any given email is spam or not, at scale. To do this, we will build a dataset from two separate sources – the popular Enron email corpus as a proxy for email that is not spam, and a collection of “419” fraudulent emails as a proxy for email that is spam.\r\n",
        "\r\n",
        "We will view this as a supervised classification task, where we will first train a classifier on a collection of emails labeled as either spam or not spam. \r\n",
        "\r\n",
        "In particular, we will sample the Enron Corpus – the largest public email collection, related to the notorious Enron financial scandal – as a proxy for email that are not spam, and sample “419” fraudulent emails, representing the best known type of spam, as a proxy for email that is spam. Both of these types of emails are openly available on [Kaggle](https://www.kaggle.com/wcukierski/enron-email-dataset).\r\n",
        "\r\n",
        "The Enron corpus contains about half a million emails written by employees of the Enron Corporation, as collected by the Federal Energy Commission for the purposes of investigating the collapse of the company. It has been used extensively in the literature to study machine learning methods for email applications and is often the first data source researchers working with emails look to for initial experimentation with algorithm prototypes. On Kaggle, it is\r\n",
        "available as a single-column .csv file with one email per row. Note that this data is still cleaner than one can expect to typically find in many practical applications in the wild.\r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/transfer-learning-for-natural-language-processing/spam-email-preprocessing.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "The body of the email will first be separated from the headers of the email, some statistics about the dataset will be teased out to get a sense for the data, stopwords will be removed from the email, and it will then be classified as either spam or not spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl9EgWVOay5R"
      },
      "source": [
        "### Loading and Visualizing the Fraudulent Email Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6g1Yz69a-w7"
      },
      "source": [
        "Let’s load the “419” fraudulent email corpus, so that we can have some example data in our training set representing the “spam” class.\r\n",
        "\r\n",
        "> Since this dataset comes as a .txt file, versus a .csv, the preprocessing steps are slightly different. First\r\n",
        "of all, we have to specify the encoding when reading the file as latin1, otherwise the default encoding option of\r\n",
        "utf-8 will fail. It is often the case in practice that one needs to experiment with a number of different encodings,\r\n",
        "with the aforementioned two being the most popular ones, to get some datasets to read correctly. Additionally,\r\n",
        "note that because this .txt file is one big column of emails (with headers) separated by line breaks and white\r\n",
        "space, and is not separated nicely into rows with one email per row – as was the case for the Enron corpus – we\r\n",
        "can’t use Pandas to neatly load it as was done before. We will read all the emails into a single string, and split\r\n",
        "the string on a code word that appears close to the beginning of each email’s header, i.e, “From r”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoaktA_bbB7e"
      },
      "source": [
        "filepath = \"./fradulent_emails.txt\"\r\n",
        "with open(filepath, \"r\", encoding=\"latin1\") as file:\r\n",
        "  data = file.read()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bmdi9UxbHDo"
      },
      "source": [
        "Split on the code word From r appearing close to the beginning of each email"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DydgG-oQbJcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a3026d3b-184f-4121-e5dd-e1445547da6b"
      },
      "source": [
        "fraud_emails = data.split(\"From r\")\r\n",
        "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully loaded 3978 spam emails!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqSaPXPlbLfb"
      },
      "source": [
        "Now that the fraudulent data is loaded as a list, we can convert it into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boolbOhybOhv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ea3ca0b2-7c09-4097-c6be-58355c402e8a"
      },
      "source": [
        "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails, columns=[\"message\"], dtype=str))\r\n",
        "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\r\n",
        "\r\n",
        "fraud_bodies_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully retrieved message body from e-mails!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear sir, \\n \\nIt is with a heart full of hope...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-2...\n",
              "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...\n",
              "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...\n",
              "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...\n",
              "4  Dear sir, \\n \\nIt is with a heart full of hope..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFjsooY28CFg"
      },
      "source": [
        "### Loading and Visualizing the Enron Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9JO_OyeelZC"
      },
      "source": [
        "The first thing we need to do is load the data with the popular Pandas library, and to take a peek at a slice of the data to make sure we have a good sense of what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qxnwX82fZAE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "baeb3d96-cfa2-4d4d-8ad7-9810f2f4b34d"
      },
      "source": [
        "filepath = \"./emails.csv\"\r\n",
        "\r\n",
        "# Read the enron data into a pandas.DataFrame called emails\r\n",
        "emails = pd.read_csv(filepath)\r\n",
        "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\r\n",
        "print(emails.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully loaded 517401 rows and 2 columns!\n",
            "                       file                                            message\n",
            "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
            "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
            "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
            "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
            "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rYJUDMShrGg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cd5dfeaa-1c5d-4498-ae6b-6277f0e77ad6"
      },
      "source": [
        "# take a closer look at the first email\r\n",
        "print(emails.loc[0][\"message\"])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
            "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
            "From: phillip.allen@enron.com\n",
            "To: tim.belden@enron.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
            "X-Origin: Allen-P\n",
            "X-FileName: pallen (Non-Privileged).pst\n",
            "\n",
            "Here is our forecast\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG5cG3UpiqNs"
      },
      "source": [
        "We see that the messages are contained within the message column of the resulting DataFrame, with the extra fields at the beginning of each message – including Message ID, To, From, etc.,– being referred to as the message’s header information or simply header.\r\n",
        "\r\n",
        "Traditional spam classification methods derive features from the header information for classifying the message as spam or not. Here, we would like to perform the same task based on the content of the message only. One possible motivation for this approach is the fact that email training data may often be de-identified in practice due to privacy concerns and regulations, thereby making header info unavailable. Thus, we need to separate the headers from the messages in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3t4cgehjw3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0e03df9d-767a-4535-8493-4c87fb2ac032"
      },
      "source": [
        "bodies = extract_messages(emails)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully retrieved message body from e-mails!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp43leIyj6iB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cbb8ce03-b182-4e2f-a48d-b2f206f2018d"
      },
      "source": [
        "# We then can display some processed emails\r\n",
        "bodies_df = pd.DataFrame(bodies)\r\n",
        "print(bodies_df.head())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   0\n",
            "0                          Here is our forecast\\n\\n \n",
            "1  Traveling to have a business meeting takes the...\n",
            "2                     test successful.  way to go!!!\n",
            "3  Randy,\\n\\n Can you send me a schedule of the s...\n",
            "4                Let's shoot for Tuesday at 11:45.  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8b-w2r3kbRK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "769543ed-34aa-465d-ba71-41519518917c"
      },
      "source": [
        "# extract random 10000 enron email bodies for building dataset\r\n",
        "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\r\n",
        "\r\n",
        "# expand default pandas display options to make emails more clearly visible when printed\r\n",
        "pd.set_option(\"display.max_colwidth\", 300)\r\n",
        "# you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames\r\n",
        "bodies_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tracy,\\n\\nI have reconciled the detail file on these and no other ETS company is picking up the costs.  I will be sending a detailed list of the companies to receive restricted stock with the final allocations on Wednesday.\\n\\nDawn\\n\\n -----Original Message-----\\nFrom: \\tGeaccone, Tracy  \\nSent:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>----- Forwarded by Tana Jones/HOU/ECT on 11/10/2000 09:04 AM -----\\n\\n\\tBradley Diebner\\n\\t11/10/2000 07:54 AM\\n\\t\\t \\n\\t\\t To: Karen Lambert/HOU/ECT@ECT, Tana Jones/HOU/ECT@ECT, Samuel \\nSchott/HOU/ECT@ECT, Mark Taylor/HOU/ECT@ECT, Brant Reves/HOU/ECT@ECT, Debbie \\nR Brackett/HOU/ECT@ECT, David...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Monika -\\n\\nI received some info today in the mail regarding a new master of science\\nprogram in quantitative financial economics. It is being offered by\\nOklahoma State University and they have a lot of money for financial\\nsupport. Perhaps you should consider it.\\n\\nIf you send me your address...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dear class,\\n\\n1. Popular acclimation has requested that we move macro the exam to Thursday\\n12/16. If you are one of the 3 people who prefered Wednesday, please contact \\nme\\nand we will arrange an opportunity for you to take the exam Wednesday.\\n        BA201B Thursday, 12/16 6-9:30 in C210 &amp; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>per Jennifer Staton 6-6269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                             0\n",
              "0  Tracy,\\n\\nI have reconciled the detail file on these and no other ETS company is picking up the costs.  I will be sending a detailed list of the companies to receive restricted stock with the final allocations on Wednesday.\\n\\nDawn\\n\\n -----Original Message-----\\nFrom: \\tGeaccone, Tracy  \\nSent:...\n",
              "1  ----- Forwarded by Tana Jones/HOU/ECT on 11/10/2000 09:04 AM -----\\n\\n\\tBradley Diebner\\n\\t11/10/2000 07:54 AM\\n\\t\\t \\n\\t\\t To: Karen Lambert/HOU/ECT@ECT, Tana Jones/HOU/ECT@ECT, Samuel \\nSchott/HOU/ECT@ECT, Mark Taylor/HOU/ECT@ECT, Brant Reves/HOU/ECT@ECT, Debbie \\nR Brackett/HOU/ECT@ECT, David...\n",
              "2  Monika -\\n\\nI received some info today in the mail regarding a new master of science\\nprogram in quantitative financial economics. It is being offered by\\nOklahoma State University and they have a lot of money for financial\\nsupport. Perhaps you should consider it.\\n\\nIf you send me your address...\n",
              "3  Dear class,\\n\\n1. Popular acclimation has requested that we move macro the exam to Thursday\\n12/16. If you are one of the 3 people who prefered Wednesday, please contact \\nme\\nand we will arrange an opportunity for you to take the exam Wednesday.\\n        BA201B Thursday, 12/16 6-9:30 in C210 & ...\n",
              "4                                                                                                                                                                                                                                                                                   per Jennifer Staton 6-6269"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjzHW02yni9B"
      },
      "source": [
        "The following (commented out) code is arguably the more \"pythonic\" way of achieving the extraction of bodies from messages. It is only 2 lines long and achieves the same result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g87bYPnnjNe"
      },
      "source": [
        "#messages = emails[\"message\"].apply(email.message_from_string)\r\n",
        "#bodies_df = messages.apply(lambda x: x.get_payload()).sample(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXoqMRdwC65"
      },
      "source": [
        "### Email text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeeYY2_OuxYw"
      },
      "source": [
        "Having loaded both datasets, we are now ready to sample emails from each one into a single DataFrame that will represent the overall dataset covering both classes of emails. Before doing this, we must decide how many samples to draw from each class. Ideally, the number of samples in each class will represent the natural distribution of emails in the wild, i.e, if we expect our classifier to encounter 60% spam emails and 40% nonspam emails when deployed, then a ratio such as 600 to 400 respectively might make sense.\r\n",
        "\r\n",
        "**Note that a severe imbalance in the data, such as 99% for nonspam and 1% for spam may overfit to predict nonspam most of the time, an issue than needs to be considered when building datasets.** Since this is an idealized experiment, and we do not have any information on natural distributions of classes, we will\r\n",
        "assume a 50/50 split. \r\n",
        "\r\n",
        "We also need to give some thought to how we are going to tokenize the emails, i.e., split emails into subunits of text - words, sentences, etc. To start off, we will tokenize into words, as this is the most common approach. \r\n",
        "\r\n",
        "We must also decide the maximum number of tokens per email, and the maximum length of each token, to ensure that the occasional “extremely long” email does not bog down the performance of our classifier. \r\n",
        "\r\n",
        "We do all these by specifying the following general hyperparameters, which will later be tuned experimentally to enhance performance as needed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_qzNMcNsGh-"
      },
      "source": [
        "n_sample = 1000   # number of samples to generate in each class - 'spam', 'not spam'\r\n",
        "maxtokens = 200    # the maximum number of tokens per document\r\n",
        "maxtokenlen = 100  # the maximum length of each token"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRVD-qopxT2f"
      },
      "source": [
        "With these hyperparameters specified, we can now create a single DataFrame for the overarching training dataset. Let’s take the opportunity to also perform remaining preprocessing tasks, namely removing stop words, punctuations and tokenizing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2OTWZJ6w9-J"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-dJjXYvxaK9"
      },
      "source": [
        "Let’s proceed by defining a function to tokenize emails by splitting them into words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42b-458pwdRh"
      },
      "source": [
        "def tokenize(row):\r\n",
        "  if row is None or row is \"\":\r\n",
        "    tokens = \"\"\r\n",
        "  else:\r\n",
        "    tokens = str(row).split(\" \")[:maxtokens]\r\n",
        "  return tokens"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_viulZEyUNO"
      },
      "source": [
        "#### Remove punctuation and unnecessary characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MOkUJbxyUeG"
      },
      "source": [
        "Taking another look at the emails on the previous pair of pages, we see that they contain a lot of punctuation characters, and the spam emails tend to be capitalized. \r\n",
        "\r\n",
        "**In order to ensure that classification is done based on language content only, we have to remove punctuation marks and other non-word characters from the emails.** We do this by employing regular expressions with the Python regex library. We also normalize words by turning them into lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n-aNOVNx3mC"
      },
      "source": [
        "def reg_expressions(row):\r\n",
        "  tokens = []\r\n",
        "  try:\r\n",
        "    for token in row:\r\n",
        "      token = token.lower()          # make all characters lower case\r\n",
        "      token = re.sub(r\"[\\W\\d]\", \"\", token)\r\n",
        "      token = token[:maxtokenlen]    # truncate all tokens to hyperparameter maxtokenlen\r\n",
        "      tokens.append(token)\r\n",
        "  except:\r\n",
        "    token = \"\"\r\n",
        "    tokens.append(token)\r\n",
        "  return tokens"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubr6_29dzvyA"
      },
      "source": [
        "#### Stop-word removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjpNoFWhzwqu"
      },
      "source": [
        "Finally, let’s define a function to remove stopwords - words that occur so frequently in language that they offer no useful information for classification. This includes words such as “the” and “are”, and the popular library NLTK provides a heavily used list that we will employ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fyCvyDzpFd"
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\r\n",
        "\r\n",
        "def stop_word_removal(row):\r\n",
        "  token = [token for token in row if token not in stop_words]\r\n",
        "  token = filter(None, token)\r\n",
        "\r\n",
        "  return token"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A14TaVP2Rro"
      },
      "source": [
        "### Assemble both Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwhmZaVb2VDS"
      },
      "source": [
        "We are now going to put all these functions together to build the single dataset representing both classes. Most methods expect this dataset to be a Numpy array in order to process it, so we convert it to that form after combining the emails.\r\n",
        "\r\n",
        "Now, putting all the preprocessing steps together we assemble our dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2rjwJFC0i7U"
      },
      "source": [
        "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\r\n",
        "\r\n",
        "# Apply predefined processing functions\r\n",
        "enron_emails = bodies_df.iloc[:, 0].apply(tokenize)\r\n",
        "enron_emails = enron_emails.apply(stop_word_removal)\r\n",
        "enron_emails = enron_emails.apply(reg_expressions)\r\n",
        "# sample the right number of emails from each class.\r\n",
        "enron_emails = enron_emails.sample(n_sample)\r\n",
        "\r\n",
        "# Apply predefined processing functions\r\n",
        "spam_emails = fraud_bodies_df.iloc[:, 0].apply(tokenize)\r\n",
        "spam_emails = spam_emails.apply(stop_word_removal)\r\n",
        "spam_emails = spam_emails.apply(reg_expressions)\r\n",
        "# sample the right number of emails from each class.\r\n",
        "spam_emails = spam_emails.sample(n_sample)\r\n",
        "\r\n",
        "# convert to Numpy array\r\n",
        "raw_data = pd.concat([enron_emails, spam_emails], axis=0).values"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siEiJQvp4Q29"
      },
      "source": [
        "Now, let’s take a peek at the result to make sure things are proceeding as expected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSd-Yfri4KaB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "00b02c0e-0ca8-4fbf-e759-41466573e28f"
      },
      "source": [
        "print(\"Shape of combined data is:\", raw_data.shape)\r\n",
        "print(\"Data is:\")\r\n",
        "print(raw_data)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of combined data is: (2000,)\n",
            "Data is:\n",
            "[list(['ercot', 'traderswe', 'going', 'live', 'curve', 'manager', 'ercot', 'monday', 'november', 'th', 'ercot', 'south', 'r', 'primary', 'curve', 'mark', 'others', 'dependent', 'upon', 'curve', 'i', 'know', 'first', 'days', 'learning', 'experience', 'ready', 'mark', 'curves', 'let', 'know', 'ill', 'come', 'sit', 'guysthanksandrea'])\n",
            " list(['teco', 'tap', '', '', 'enron', '', '', '', 'hpl', 'ifercls', 'hpl', 'lsk', 'ic', '', '', 'enron'])\n",
            " list(['', 'forwarded', 'darron', 'c', 'gironhouect', '', '', 'am', '', 'enron', 'north', 'america', 'corpfrom', 'darron', 'c', 'giron', '', '', 'amto', 'kristigironcfisdnetcc', 'subject', 'kids', 'find', 'contested', 'ballot', 'childs', 'play', 'forwarded', 'darron', 'c', 'gironhouect', '', '', 'am', 'greg', 'couch', '', 'pmto', 'darron', 'c', 'gironhouectect', 'david', 'lorenzcorpenronenroncc', 'subject', 'kids', 'find', 'contested', 'ballot', 'childs', 'play', 'forwarded', 'greg', 'couchhouect', '', '', 'pm', 'vance', 'norman', 'nvancehesscom', '', '', 'pmto', 'greg', 'couch', 'email', 'gregcouchenroncomcc', 'subject', 'kids', 'find', 'contested', 'ballot', 'childs', 'playfriday', 'november', '', 'in', 'the', 'newskids', 'find', 'contested', 'ballot', 'childs', 'playthe', 'shreveport', 'times', 'don', 'walkerits', 'ballot', 'perplexed', 'florida', 'voters', 'match', 'witsof', 'first', 'fourthgraders', 'stockwell', 'elementary', 'school', 'bossier', 'citydisillusioned', 'upset', 'lingering', 'chaos', 'weeks', 'presidentialelection', 'fourthgrade', 'teacher', 'lisa', 'burns', 'pulled', 'sample', 'thecontroversial', 'palm', 'beach', 'county', 'fla', 'ballot', 'internet', 'thursdayshe', 'put', 'class', '', 'yearolds', 'test', 'i'])\n",
            " ...\n",
            " list(['emailmessagemessage', 'object', 'xfcba', 'emailmessagemessage', 'object', 'xfcf'])\n",
            " list(['shell', 'petroleum', 'development', 'company', '', 'marinac', 'lagos', 'nigeriaeour', 'refespdcfattentiona', 'the', 'managing', 'directorcsircfirstc', 'i', 'must', 'solicit', 'your', 'confidence', 'in', 'this', 'transactionc', 'this', 'is', 'by', 'virtue', 'of', 'its', 'nature', 'as', 'being', 'confidentiale', 'i', 'am', 'assuring', 'you', 'that', 'all', 'will', 'be', 'well', 'at', 'the', 'end', 'of', 'he', 'daye', 'we', 'have', 'decided', 'to', 'contact', 'you', 'by', 'email', 'due', 'to', 'the', 'urgency', 'of', 'this', 'transactionelet', 'me', 'start', 'by', 'introducing', 'my', 'self', 'properly', 'to', 'youe', 'i', 'am', 'mr', 'danjuma', 'williams', 'mc', 'the', 'auditor', 'of', 'the', 'shell', 'petroleum', 'development', 'company', 'spdce', 'i', 'came', 'to', 'know', 'of', 'you', 'in', 'my', 'private', 'search', 'for', 'a', 'reliable', 'and', 'reputable', 'person', 'to', 'handle', 'this', 'confidentialtransaction', 'which', 'involves', 'the', 'transfer', 'of', 'the', 'sum', 'of', 'ninefive', 'million', 'united', 'states', 'dollars', 'with', 'security', 'company', 'in', 'europeethis', 'amount', 'was', 'secured', 'from', 'excess', 'oil', 'sales', 'from', 'nigeria', 'crude', 'oile', 'the', 'sum', 'of', 'e', 'billion', 'oil', 'windfall', 'was', 'reliezed', 'by', 'the', 'shell', 'petroleumdevelopment', 'company', 'for', 'the', 'month', 'of', 'august', 'eorganisation', 'of', 'petroleum', 'exporting', 'countries', 'opec', 'crude', 'oil', 'price', 'was', 'peg', 'at', 'e', 'per', 'barrel', 'and', 'fortunately', 'for', 'oil', 'producing', 'countries', 'like', 'nigeriac', 'there', 'was', 'rises', 'in', 'oil', 'price', 'to', 'about', 'e', 'and', 'e', 'per', 'barrel', 'and', 'as', 'a', 'result', 'there', 'was', 'excess', 'oil', 'sales', 'and', 'i', 'believe'])\n",
            " list(['emailmessagemessage', 'object', 'xfccba', 'emailmessagemessage', 'object', 'xfcbc'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXy7SLuV44Xw"
      },
      "source": [
        "We see that the resulting array has divided the text into word units, as we intended to.\r\n",
        "\r\n",
        "Let’s create the headers corresponding to these emails, consisting of n_sample=1000 of spam emails followed by n_sample=1000 of non-spam emails:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2hCPV3z4qXn"
      },
      "source": [
        "categories = [\"spam\", \"notspam\"]\r\n",
        "header = ([1] * n_sample)\r\n",
        "header.extend(([0] * n_sample)) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9La125o61fZ"
      },
      "source": [
        "We are now ready to convert this Numpy array into numerical features that can actually be fed to the algorithms for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj0jsZ9W65Yo"
      },
      "source": [
        "### Converting the data to the form expected by Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALmmE6Wo7A-6"
      },
      "source": [
        "Before using this function to train a model, we will need to adapt our preprocessed data a bit for this model architecture.\r\n",
        "\r\n",
        "We use the below function to combine each such list into a single text string. This is the format in which the BERT TensorFlow hub model expects the input, and we are glad to oblige.\r\n",
        "\r\n",
        "> **NOTE**: The combined string in this case has stopwords removed – steps that are often not required in deep learning practice due to the uncanny ability of artificial neural networks to figure out what is important and isn’t,\r\n",
        "i.e., feature engineering, automatically. In our case, since we are trying to compare the strengths and weaknesses of the different model types for this problem, applying the same kind of preprocessing for all algorithms makes sense and is arguably the right approach. We note however that ELMo was pretrained on a corpus containing stopwords, as was BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etyyQh-ZWWXf"
      },
      "source": [
        "Having fully vectorized the dataset, we must remember that it is not shuffled with respect to classes, i.e., it contains Nsamp = 1000 spam emails followed by an equal number of nonspam emails. Depending on how this dataset is split, in our case by picking the first 70% for training and the remainder for testing, this could lead to a training set composed of spam only, which would obviously lead to failure. In order to create a randomized ordering of class samples in the dataset, we will need to shuffle the data in unison with the header/list of labels.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1jUL1YnVBQN"
      },
      "source": [
        "# shuffle raw data first\r\n",
        "def unison_shuffle_data(data, header):\r\n",
        "  p = np.random.permutation(len(header))\r\n",
        "  data = data[p]\r\n",
        "  header = np.asarray(header)[p]\r\n",
        "\r\n",
        "  return data, header"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Fy3piLUjSq"
      },
      "source": [
        "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\r\n",
        "def convert_data(raw_data, header):\r\n",
        "  converted_data, labels = [], []\r\n",
        "  for i in range(raw_data.shape[0]):\r\n",
        "    # combine list of tokens representing each email into single string\r\n",
        "    out = \" \".join(raw_data[i])\r\n",
        "    converted_data.append(out)\r\n",
        "    labels.append(header[i])\r\n",
        "  converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\r\n",
        "\r\n",
        "  return converted_data, np.array(labels)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIGDs4kZYCIr"
      },
      "source": [
        "As the very last step of preparing the email dataset for training by our baseline classifiers, we split it into independent training and testing or validation sets. This will allow us to evaluate the performance of the classifier on a set of data that was not used for training, an important thing\r\n",
        "to ensure in machine learning practice. We elect to use 70% of the data for training, and 30% for testing/validation afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2bJ0TlTX3FW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426b05f9-005b-4c1f-9962-fbcc6e655714"
      },
      "source": [
        "raw_data, header = unison_shuffle_data(raw_data, header)\r\n",
        "\r\n",
        "# split into independent 70% training and 30% testing sets\r\n",
        "idx = int(0.7 * raw_data.shape[0])  # get 70% index value\r\n",
        "\r\n",
        "# 70% of data for training\r\n",
        "train_x, train_y = convert_data(raw_data[:idx], header[:idx])\r\n",
        "\r\n",
        "# remaining 30% for testing\r\n",
        "test_x, test_y = convert_data(raw_data[idx:], header[idx:])\r\n",
        "\r\n",
        "print(\"train_x/train_y list details, to make sure they are of the right form:\")\r\n",
        "print(len(train_x))\r\n",
        "print(train_x)\r\n",
        "print(len(train_y))\r\n",
        "print(train_y[:5])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x/train_y list details, to make sure they are of the right form:\n",
            "1400\n",
            "[['dear friendthrough the courtesy of business opportunity i take liberty anchored on astrong desire to solicit your assistance on this mutually beneficial andriskfree transaction which i hope you will give your urgent attentioni am mrsesay massaquoe i am moved to write you this letter this was inconfidence considering our present circumstance and situationi escaped with my wife and children out of sierra leone togroujirnssuma village in the netherlands through the aid of the unitednations evacuation team where we are now presently residing on temporarypolitical asylumhowever due to this situation i decided to change most of my billions ofdollars deposited in swiss bank and other countries into other forms ofmoney coded for safe purpose because the new head of states ahmed tejankabba made arrangements with the swiss government and other europeancountries to freeze all my treasures deposited in some europeancountrieshence i and my wife along with my children decided laying lowin this our tempoery political asylum camp here in grou jirnssum in thenetherlands to study the situation till when things gets bettersincepresident tejan kabba taking over government again in sierraleone one ofmy chateaux in southern france was confiscated by the frenchgovernmentand as such we had']\n",
            " ['hello vincemy name fati liamidi i work associate urm group ees i come value proposition i think could make sense formy group wanted run one colleagues see could help terms pricing would mind directing toward somebody group would willing talk me the idea involves options thanks much advance fati liamidi']\n",
            " ['please cancel kay manns membership she paid december   thanksgeorgia']\n",
            " ...\n",
            " ['i want check page storage wd nov through  actuals i show wd  dth storage  adjusted tco fuel cg could please let know at per proxy targeting wd sto   cg   for eom let know jpp']\n",
            " ['email address williammabayenetscapenettelephone number dear friend i wish begin way introduction i william mabaye first surviving son late tutu mabaye one foremost rich black farmers zimbabwe recently murdered land dispute country before death father taken johannesburgsouth africa deposit sum us million tweenty five million united states dollars one private security companies family valuables realized looming danger zimbabwe this amount meant purchase new machineries chemicals farms also establishment new farms swazilandthis land dispute started president robert mugabe introduced new land reform particularly targeted rich white farmers black farmers my father included this resulted gruesome killing rich farmers mainly whites unlawful possession properties mugabes war veterans disguise fighting interest country it background i fled country family netherlands currently seeking asylumi']\n",
            " ['stthomas hospitallambeth palace roadlondon se ehunitedkingdomtel   dear friend in christ i believe treat mail fear god it tears i writing mail i dont need pity love son my mail may seem painful sorrowful request pity me show love son i orphan wish son experience earth automobile crash nearly claimed life my name edward brown married late juan jbrown died two daughters indonesia th december  tsunami disaster painful sorrowful incident condition worsened i diagnosed cancer got worst i suffering heart failure hepatitis since my friends ignored due relationship god sickbed my wife children i united kingdom']]\n",
            "1400\n",
            "[0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HQRPMa4Z8RB"
      },
      "source": [
        "Since 70% of 2000 is 1400, looks good! (for n_sample=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAdf-aVkadDa"
      },
      "source": [
        "## Neural Network Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyHf2bhnaeI8"
      },
      "source": [
        "Neural networks are the most important class of machine learning algorithms for handling perceptual problems such as computer vision and NLP.\r\n",
        "\r\n",
        "we will train two representative pretrained neural network language models\r\n",
        "on the two illustrative example problems we have been baselining.\r\n",
        "\r\n",
        "The two models we will consider here are:\r\n",
        "\r\n",
        "- **ELMo** – Embeddings from Language Models, and\r\n",
        "- **BERT** – Bidirectional Encoder Representations from Transformers.\r\n",
        "\r\n",
        "ELMo includes elements of convolutional and recurrent (specifically LSTM) elements, while the appropriately named BERT is transformer-based.\r\n",
        "\r\n",
        "The simplest form of transfer learning fine-tuning will be employed, where a single dense classification layer is trained on top of the corresponding pretrained embedding over our dataset of labels.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHMpH7umylgU"
      },
      "source": [
        "### Bidirectional Encoder Representations from Transformers (BERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL3uRvZsyl91"
      },
      "source": [
        "**Bidirectional Encoder Representations from Transformers (BERT) model** was also named after a popular Sesame Street character as a nod to the trend started by ELMo. BERT variants achieve some of the best performance in transferring pretrained language model knowledge to downstream NLP tasks. The model was similarly trained to predict words in a sequence of words, although the exact masking procedure is somewhat different. It can also be done in an unsupervised manner on very large corpuses, and the resulting weights similarly\r\n",
        "generalize to a variety of other NLP tasks. **Arguably, to familiarize oneself with transfer learning in NLP, it is indispensable for one to familiarize oneself with BERT.**\r\n",
        "\r\n",
        "It will suffice to mention here that the model employs character-level convolutions to build up preliminary embeddings of word tokens, followed by transformer-based encoders with selfattention layers that provide the model with a context of surrounding words. **The transformer functionally replaced the role of the bidirectional LSTMs employed by ELMo. Transformers have some advantages versus LSTMs with respect to training scalability as well.**. Again, we will use Keras with Tensorflow backend to build our model.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZQZ0weNfaJY"
      },
      "source": [
        "### Define BERT layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYjdm_U-fcNM"
      },
      "source": [
        "The BERT model is also available through the Tensorflow Hub. In order to\r\n",
        "make the hub model usable by Keras, we similarly define a custom Keras layer that instantiates it in the right format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUorbYbDZw8b"
      },
      "source": [
        "class BertLayer(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "  def __init__(self, n_fine_tune_layers=10, pooling=\"mean\", bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\", **kwargs):\r\n",
        "    self.n_fine_tune_layers = n_fine_tune_layers    # Default number of top layers to unfreeze for training\r\n",
        "    self.trainable = True\r\n",
        "    self.output_size = 768      # BERT embedding dimension, i.e., size of resulting output semantic vectors\r\n",
        "    self.pooling = pooling      # Choice of regularization type\r\n",
        "    self.bert_path = bert_path  # Pretrained model to use, this is the large uncased original version of the model\r\n",
        "\r\n",
        "    if self.pooling not in [\"first\", \"mean\"]:\r\n",
        "      raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\r\n",
        "\r\n",
        "    super(BertLayer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    \"\"\"function for building BERT embedding\"\"\"\r\n",
        "    # Download pretrained BERT model from Tensorflow Hub\r\n",
        "    self.bert = hub.Module(self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\") \r\n",
        "\r\n",
        "    # Remove unused layers\r\n",
        "    trainable_vars = self.bert.variables\r\n",
        "    if self.pooling == \"first\":\r\n",
        "      trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\r\n",
        "      trainable_vars = [\"pooler/dense\"]\r\n",
        "    elif self.pooling == \"mean\":\r\n",
        "      trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name and not \"/pooler/\" in var.name]\r\n",
        "      trainable_vars = []\r\n",
        "    else:\r\n",
        "      raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\r\n",
        "    \r\n",
        "    # Select how many layers to fine tune\r\n",
        "    for i in range(self.n_fine_tune_layers):\r\n",
        "      trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\r\n",
        "\r\n",
        "    # Update trainable vars to contain only the specified layers\r\n",
        "    trainable_vars = [var for var in trainable_vars if any([layer in var.name for layer in trainable_vars])]\r\n",
        "\r\n",
        "    # Add to trainable weights\r\n",
        "    for var in trainable_vars:\r\n",
        "      self._trainable_weights.append(var)\r\n",
        "\r\n",
        "    for var in self.bert.variables:\r\n",
        "      if var not in self._trainable_weights:\r\n",
        "        self._non_trainable_weights.append(var)\r\n",
        "\r\n",
        "    super(BertLayer, self).build(input_shape)\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    \"\"\"specify function for calling embedding\"\"\"\r\n",
        "    inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\r\n",
        "    input_ids, input_mask, segment_ids = inputs\r\n",
        "    # Inputs to BERT take a very specific triplet form\r\n",
        "    bert_inputs = dict(\r\n",
        "        input_ids = input_ids,\r\n",
        "        input_mask = input_mask,\r\n",
        "        segment_ids = segment_ids\r\n",
        "    )\r\n",
        "    \r\n",
        "    if self.pooling == \"first\":\r\n",
        "      pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\"pooled_output\"]\r\n",
        "    elif self.pooling == \"mean\":\r\n",
        "      result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\"sequence_output\"]\r\n",
        "      # BERT “masks” some words and then attempts to predict them as learning target\r\n",
        "      mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\r\n",
        "      masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\r\n",
        "      input_mask = tf.cast(input_mask, tf.float32)\r\n",
        "      pooled = masked_reduce_mean(result, input_mask)\r\n",
        "    else:\r\n",
        "      raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\r\n",
        "\r\n",
        "    return pooled\r\n",
        "\r\n",
        "  def compute_output_shape(self, input_shape):\r\n",
        "    \"\"\"specify output shape\"\"\"\r\n",
        "    return (input_shape[0], self.output_size)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Cg9jShftQj"
      },
      "source": [
        "### Build BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hed2Z4FrysZV"
      },
      "source": [
        "We now use the custom TF hub ELMo embedding layer within a higher-level function to define the overall model. More specifically, we put a dense trainable layer of output dimension 256 on top of the ELMo embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vobk4LfyqQ9"
      },
      "source": [
        "def build_model():\r\n",
        "  input_text = layers.Input(shape=(1,), dtype=\"string\")\r\n",
        "  embedding = ElmoEmbeddingLayer()(input_text)\r\n",
        "  dense = layers.Dense(256, activation=\"relu\")(embedding)      # new layer outputting 256-dimensional feature vectors\r\n",
        "  prediction = layers.Dense(1, activation=\"sigmoid\")(dense)\r\n",
        "\r\n",
        "  # we could use sigmoid activation as well, but we choose softmax\r\n",
        "  # to enable us use sparse_categorical_crossentropy and sparse_categorical_accuracy below\r\n",
        "  model = Model(inputs=[input_text], outputs=prediction)\r\n",
        "  # use sparse_categorical_crossentropy and sparse_categorical_accuracy do avoid having to one-hot encode the labels\r\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qmvd5bThBLK",
        "outputId": "a5381581-4f9a-466d-c163-2a1521dbdaf2"
      },
      "source": [
        "# Build and fit\r\n",
        "model = build_model()\r\n",
        "history = model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=5, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "elmo_embedding_layer_1 (Elmo (None, 1024)              4         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 262,661\n",
            "Trainable params: 262,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1400 samples, validate on 600 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1400/1400 [==============================] - 79s 57ms/step - loss: 0.3709 - acc: 0.8779 - val_loss: 0.1038 - val_acc: 0.9883\n",
            "Epoch 2/5\n",
            "1400/1400 [==============================] - 36s 25ms/step - loss: 0.3254 - acc: 0.9343 - val_loss: 0.1393 - val_acc: 0.9650\n",
            "Epoch 3/5\n",
            "1400/1400 [==============================] - 35s 25ms/step - loss: 0.1886 - acc: 0.9621 - val_loss: 0.1262 - val_acc: 0.9583\n",
            "Epoch 4/5\n",
            "1400/1400 [==============================] - 35s 25ms/step - loss: 0.0696 - acc: 0.9850 - val_loss: 0.0405 - val_acc: 0.9917\n",
            "Epoch 5/5\n",
            "1400/1400 [==============================] - 35s 25ms/step - loss: 0.0931 - acc: 0.9850 - val_loss: 0.0593 - val_acc: 0.9883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj2NGhaGnOLa"
      },
      "source": [
        "# Save trained model\r\n",
        "model.save(\"ELMoModel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQYnKh_-lXTh"
      },
      "source": [
        "First of all, notice that we have added an additional layer on top the pretrained ELMo embedding, producing 256-dimensional feature vectors. We have also added a classification layer of output dimension 1. The activation function ‘sigmoid’ transforms its input into the interval between 0 and 1.\r\n",
        "\r\n",
        "Its output can be interpreted as the probability of the positive class, and when it exceeds some prespecified threshold (usually 0.5) the corresponding input to the network can be classified as the said positive class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijD8G8DVyw7_"
      },
      "source": [
        "We note that most of the trainable parameters in this case (approximately 260 thousand of them) are coming from the layers we added on top of the custom ELMo model. In other words, this is our first instance of transfer learning – learning a pair of new layers on top of the pretrained model shared by ELMo’s creators.\r\n",
        "\r\n",
        "In practice, one can increase the value of this parameter until the speed of convergence of a typical problem instance does not benefit from the increase, or whenever the GPU memory is no longer large enough for a single data batch to\r\n",
        "fit on it during an iteration of the algorithm, whichever happens first. Additionally, when dealing with a multi-GPU scenario, some evidence that the optimal scaling-up schedule of the batch size is linear in the number of GPUs, has been presented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Ts1BU2mQmkT6",
        "outputId": "43e2872a-ff2d-49cf-b791-f6530bd32d4a"
      },
      "source": [
        "df_history = pd.DataFrame(history.history)\r\n",
        "\r\n",
        "fig,ax = plt.subplots()\r\n",
        "plt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\r\n",
        "plt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.title('ELMo Email Classification Training')\r\n",
        "plt.legend(loc='best')\r\n",
        "plt.grid()\r\n",
        "plt.show()\r\n",
        "# Save figures\r\n",
        "fig.savefig('ELMoConvergence.eps', format='eps')\r\n",
        "fig.savefig('ELMoConvergence.pdf', format='pdf')\r\n",
        "fig.savefig('ELMoConvergence.png', format='png')\r\n",
        "fig.savefig('ELMoConvergence.svg', format='svg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZe6rKw7mkxq"
      },
      "source": [
        "We see that a validation accuracy of approximately 98.83% is attained at the 4th epoch, i.e., in under a minute. This performance is comparable to the performance of the logistic regression approach, which is only slightly better at 98.8%. We note that the behavior of the algorithm is stochastic, i.e., it behaves differently from run to run.\r\n",
        "\r\n",
        "Finally, we note that the divergence of training and validation accuracies is suggestive of the beginning of overfitting as indicative in the figure. This\r\n",
        "lends credence to the hypothesis that increasing the amount of signal by increasing the length of tokens, as specified by hyper-parameter maxtokenlen, and the number of tokens per email, as specified by maxtokens, may increase performance further. Naturally, increasing the number of samples per class by cranking up Nsamp should also work to improve performance.\r\n",
        "\r\n",
        "Each epoch again takes approximately 10 seconds and a validation accuracy of approximately 70% is achieved in under a minute at the 2nd epoch.\r\n",
        "\r\n",
        "**Note that some evidence of overfitting can be observed at the 3rd and later epochs, as the training accuracy continues to improve, i.e., the fit to the data improves, while the validation accuracy remains lower.**"
      ]
    }
  ]
}