{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-completion-with-gpt2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPWxHSUQayCgA/s0RYh605F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transfer-learning-for-natural-language-processing/blob/main/6-text-generation-with-gpt-2-and-gpt-3-models/text_completion_with_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TihxpsDJR1fq"
      },
      "source": [
        "## Text completion with GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nseBpmVGSBw7"
      },
      "source": [
        "This notebook will clone the OpenAI GPT-2 repository, download the 345M parameter GPT-2 transformer model, and interact with it. We will enter context sentences and analyze the text generated by the transformer. The goal is to see how it creates new content.\n",
        "\n",
        "We must activate the GPU to train our GPT-2 345M parameter transformer model.\n",
        "OpenAI has begun to offer transformers as a cloud service. However, we saw that we might be able to run small models with standard machines without going through a cloud service to run a powerful transformer GPT-3.\n",
        "\n",
        "We will use the GPT-2 model but will not train it. We could not train large GPT models even if we had access to the source code because most of us lack the computing power to do it. Because we would need petaflops with\n",
        "the more recent transformer models!\n",
        "\n",
        "An average developer does not have access to this level of machine power. Google Cloud, Microsoft Azure, Amazon Web Services (AWS), for example, can rent a certain level of machine resources in teraflops to cloud customers.\n",
        "\n",
        "If we go a step further, it becomes tougher to train transformers in teraflops. Accessing petaflops calculation power is limited to a restricted number of teams in the world.\n",
        "\n",
        "However, we will see that the results produced by the limited power of Google\n",
        "Colaboratory VMs for our 345M parameter GPT-2 are quite convincing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5JYf_1VUypz"
      },
      "source": [
        "## Step 1: Cloning the OpenAI GPT-2 repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1KSjKpDUzxY"
      },
      "source": [
        "OpenAI is still letting us download GPT-2. This may be discontinued in the future, or maybe we will have access to more resources. At this point, the evolution of transformers and their usage moves so fast nobody can foresee how the market will evolve, even the major research labs themselves.\n",
        "\n",
        "We will clone OpenAI's GitHub directory on our VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHakKl1rVP2F"
      },
      "source": [
        "!git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbG7vOrTVzA2"
      },
      "source": [
        "You can see that we do not have the Python training files we need. We will install them when we train the GPT-2 model in the Training a GPT-2 language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFhi6Xn-V4cn"
      },
      "source": [
        "## Step 2: Installing the requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayHpIY5YV6N8"
      },
      "source": [
        "The requirements will be installed automatically:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdE7wTOtXf5c"
      },
      "source": [
        "import os # when the VM restarts import os necessary\n",
        "\n",
        "os.chdir(\"/content/gpt-2\")\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Mp3IE3YAei"
      },
      "source": [
        "The requirements for this notebook are:\n",
        "\n",
        "- `Fire 0.1.3` to generate command-line interfaces (CLIs)\n",
        "- `regex 2017.4.5` for regex usage\n",
        "- `Requests 2.21.0` an HTTP library\n",
        "- `tqdm 4.31.1` to display a progress meter for loops\n",
        "\n",
        "You may be asked to restart the notebook.\n",
        "\n",
        "Do not restart it now. Let's wait until we check the version of TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E78TYMuaYW24"
      },
      "source": [
        "## Step 3: Checking the version of TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "152DPeHKYYry"
      },
      "source": [
        "The GPT-2 transformer 345M transformer model provided by OpenAI uses\n",
        "TensorFlow 1.x. In 2020, GPT models have reached 175 billion\n",
        "parameters, making it impossible for us to train them without having access to a supercomputer.\n",
        "\n",
        "The corporate giants' research labs, such as Facebook AI and OpenAI and Google\n",
        "Research/Brain, are speeding towards super-transformers and are leaving us with what they can for us to learn and understand. They do not have time to go back and update all of the models they share.\n",
        "\n",
        "This is one of the reasons for which Google Colaboratory VMs have preinstalled\n",
        "versions of both TensorFlow 1.x and TensorFlow 2.x.\n",
        "\n",
        "We will be using TensorFlow 1.x in this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaUzYNI0ZOgv"
      },
      "source": [
        "#Colab has tf 1.x and tf 2.x installed\n",
        "#Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsu361O0ZiZE"
      },
      "source": [
        "Whether version tf 1.x is displayed or not, rerun the cell to make sure, then restart the VM. Rerun this cell to make sure before continuing.\n",
        "\n",
        "If you encounter a TensforFlow error during the process (ignore the warnings), rerun this cell, restart the VM, and rerun to make sure.\n",
        "\n",
        "Do this every time you restart the VM. The default version of the VM is tf.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNIk5fi1ZqVh"
      },
      "source": [
        "## Step 4: Downloading the 345M parameter GPT-2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uAosetxZtBj"
      },
      "source": [
        "We will now download a trained 345M parameter GPT-2 model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M2g07NiaJmw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}